{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80122aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacbee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install bertopic if you don't already have it\n",
    "pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install nltk if you don't already have it\n",
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c359947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24293765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nltk libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14175162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data file, remove null Descriptions and check the first few rows\n",
    "docs = pd.read_csv(r\"[your_filepath]\\Bookshelf-2025-05-08.csv\", dtype={'Description': str}, engine = 'python')\n",
    "docs = docs[docs['Description'].notnull()]\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd38340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multilingual stopword lists\n",
    "stop_words_en = set(stopwords.words('english'))\n",
    "stop_words_he = set(stopwords.words('greek'))\n",
    "stop_words_de = set(stopwords.words('german'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d39a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove English, Greek and German stopwords from the description\n",
    "# Words need to be changed to lower case or else they remain in the list\n",
    "docs_df = pd.DataFrame(docs)\n",
    "docs_df.columns = ['Title', 'Categories', 'Description']\n",
    "docs_df['desc_without_stopwords'] = docs_df['Description'].apply(lambda x: ' '.join([word for word in x.split() if (word.lower() not in (stop_words_en)) and (word.lower() not in (stop_words_de)) and (word.lower() not in (stop_words_he))]))\n",
    "print(docs_df['desc_without_stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorizer model\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cca51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTopic needs data to be in a list, so we create the list using the descriptions without stopwords\n",
    "docs_list = docs_df['desc_without_stopwords']\n",
    "docs_list = docs_list[~pd.isna(docs_list)].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BERTopic model. Needs to be multilingual and to have small number of words per topic to categorise non-English books and books that have a small number per category\n",
    "topic_model = BERTopic(vectorizer_model=vectorizer_model, verbose = True, language = \"multilingual\", calculate_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93437eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "topics, probs = topic_model.fit_transform(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65eb673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the topics\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a topic\n",
    "topic_model.get_topic(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hierarchical cluster model of topics. This throws an error for me but still produces a dendrogram\n",
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e65f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap to show topic similarities. This throws an error for me like with the hierarchical cluster model. I find this diagram to be less useful than the dendrogram\n",
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d019daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the topic against individual documents in the list (using the description without stopwords)\n",
    "topic_model.get_document_info(docs_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
